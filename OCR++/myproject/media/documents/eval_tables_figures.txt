<<table>>
Table 1: Generic set of regular expressions for citation instance identification. Here, AN represent author name, Y represent year and I represent reference index within citation instance.
<<table>>
Table 3: Micro-average accuracy for GROBID and OCR++ for different publishing styles.

<<figure>>
Figure 1: Screenshot of pdf2xml tool output.
<<figure>>
Figure 2: OCR++ framework overview and user interface
<<figure>>
Figure 2(a) describes the sub-task dependencies in OCR++. The web interface of the tool is shown in Figure 2(b). We leverage the rich information present in the XML files to perform extraction tasks. Although each extraction task described below is performed using machine learning models as well as hand written rules/heuristics, we only include the better performing scheme in our framework. Next, we describe each extraction task in detail.
<<figure>>
Figure and table heading extraction is performed after chunking (described in Section 2.1). If the chunk starts with the word FIGURE or Figure or FIG. or Fig., then the chunk represents a figure heading. Similarly, if the chunk starts with the word Table or TABLE, then the chunk represents a table heading. However, it has been observed that table contents are also present in the chunk. Therefore, we use a feature bold font to extract bold tokens from such chunks.
<<figure>>
Figure 3: Title extraction accuracy calculated at six different years for COLING.
<<figure>>
Figure 4: Comparison between batch processing time of GROBID and OCR++.
<<figure>>
Figure 5: Sectionwise citation distribution in article dataset
